{
	data_dir: data/gtsrb-german-traffic-sign/Train
	ckpt_dir: models/adam_batchnorm_dataaug_xavier_lrscheduler_dropout0.2
	optimizer_name: adam
	batch_size: 64
	num_epochs: 30
	dropout_prob: 0.2
	learning_rate: 0.001
	num_classes: 5
	use_data_augmentation: True
	use_xavier_init: True
	use_batch_norm: True
	use_lr_scheduler: True
	seed: 123
}
device: cuda:0
number of samples:
train: 25000
val: 1000
loading train dataset from pickle file..
loading val dataset from pickle file..
initializing model params with xavier initialization
-----------------------------------------------------------------------------------------
model:
-----------------------------------------------------------------------------------------
TrafficSignsConvNet(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (relu1): ReLU()
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (dropout1): Dropout2d(p=0.2)
  (batchnorm1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))
  (relu2): ReLU()
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (dropout2): Dropout2d(p=0.2)
  (batchnorm2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(12, 18, kernel_size=(5, 5), stride=(1, 1))
  (relu3): ReLU()
  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (dropout3): Dropout2d(p=0.2)
  (batchnorm3): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(18, 24, kernel_size=(5, 5), stride=(1, 1))
  (relu4): ReLU()
  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (dropout4): Dropout2d(p=0.2)
  (batchnorm4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=384, out_features=256, bias=True)
  (reluf1): ReLU()
  (batchnormfc1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=256, out_features=64, bias=True)
  (reluf2): ReLU()
  (batchnormfc2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc3): Linear(in_features=64, out_features=5, bias=True)
)
-----------------------------------------------------------------------------------------
number of trainable params: 134603
-----------------------------------------------------------------------------------------
training..
[Epoch 1/30] loss: 1.5295, acc: 31.21 %
	(val) loss: 1.0773, acc: 60.20 %

    - found new best validation accuracy

Checkpoint Directory does not exist! Making directory models/adam_batchnorm_dataaug_xavier_lrscheduler_dropout0.2
[Epoch 2/30] loss: 0.9777, acc: 61.22 %
	(val) loss: 0.3021, acc: 90.40 %

    - found new best validation accuracy

[Epoch 3/30] loss: 0.6288, acc: 76.22 %
	(val) loss: 0.1298, acc: 95.90 %

    - found new best validation accuracy

[Epoch 4/30] loss: 0.4444, acc: 83.63 %
	(val) loss: 0.0793, acc: 97.40 %

    - found new best validation accuracy

[Epoch 5/30] loss: 0.3360, acc: 87.80 %
	(val) loss: 0.0554, acc: 98.20 %

    - found new best validation accuracy

[Epoch 6/30] loss: 0.2780, acc: 89.98 %
	(val) loss: 0.0367, acc: 98.80 %

    - found new best validation accuracy

[Epoch 7/30] loss: 0.2384, acc: 91.45 %
	(val) loss: 0.0237, acc: 99.20 %

    - found new best validation accuracy

[Epoch 8/30] loss: 0.2059, acc: 92.70 %
	(val) loss: 0.0190, acc: 99.50 %

    - found new best validation accuracy

[Epoch 9/30] loss: 0.1820, acc: 93.57 %
	(val) loss: 0.0134, acc: 99.80 %

    - found new best validation accuracy

[Epoch 10/30] loss: 0.1644, acc: 94.15 %
	(val) loss: 0.0109, acc: 99.80 %

    - found new best validation accuracy

Epoch    10: reducing learning rate of group 0 to 5.0000e-04.
[Epoch 11/30] loss: 0.1376, acc: 95.21 %
	(val) loss: 0.0308, acc: 99.60 %

Epoch    11: reducing learning rate of group 0 to 2.5000e-04.
[Epoch 12/30] loss: 0.1208, acc: 95.76 %
	(val) loss: 0.0215, acc: 99.60 %

Epoch    12: reducing learning rate of group 0 to 1.2500e-04.
[Epoch 13/30] loss: 0.1131, acc: 95.99 %
	(val) loss: 0.0100, acc: 99.80 %

    - found new best validation accuracy

Epoch    13: reducing learning rate of group 0 to 6.2500e-05.
[Epoch 14/30] loss: 0.1067, acc: 96.28 %
	(val) loss: 0.0193, acc: 99.60 %

Epoch    14: reducing learning rate of group 0 to 3.1250e-05.
[Epoch 15/30] loss: 0.1008, acc: 96.51 %
	(val) loss: 0.0127, acc: 99.70 %

Epoch    15: reducing learning rate of group 0 to 1.5625e-05.
[Epoch 16/30] loss: 0.1015, acc: 96.42 %
	(val) loss: 0.0105, acc: 99.80 %

    - found new best validation accuracy

Epoch    16: reducing learning rate of group 0 to 7.8125e-06.
[Epoch 17/30] loss: 0.1022, acc: 96.57 %
	(val) loss: 0.0094, acc: 99.70 %

Epoch    17: reducing learning rate of group 0 to 3.9063e-06.
[Epoch 18/30] loss: 0.1019, acc: 96.38 %
	(val) loss: 0.0185, acc: 99.60 %

Epoch    18: reducing learning rate of group 0 to 1.9531e-06.
[Epoch 19/30] loss: 0.0987, acc: 96.59 %
	(val) loss: 0.0179, acc: 99.80 %

    - found new best validation accuracy

Epoch    19: reducing learning rate of group 0 to 9.7656e-07.
[Epoch 20/30] loss: 0.1009, acc: 96.39 %
	(val) loss: 0.0172, acc: 99.80 %

    - found new best validation accuracy

Epoch    20: reducing learning rate of group 0 to 4.8828e-07.
[Epoch 21/30] loss: 0.1041, acc: 96.40 %
	(val) loss: 0.0138, acc: 99.60 %

Epoch    21: reducing learning rate of group 0 to 2.4414e-07.
[Epoch 22/30] loss: 0.1029, acc: 96.42 %
	(val) loss: 0.0103, acc: 99.70 %

Epoch    22: reducing learning rate of group 0 to 1.2207e-07.
[Epoch 23/30] loss: 0.1029, acc: 96.32 %
	(val) loss: 0.0206, acc: 99.70 %

Epoch    23: reducing learning rate of group 0 to 6.1035e-08.
[Epoch 24/30] loss: 0.0981, acc: 96.59 %
	(val) loss: 0.0132, acc: 99.60 %

Epoch    24: reducing learning rate of group 0 to 3.0518e-08.
[Epoch 25/30] loss: 0.0982, acc: 96.50 %
	(val) loss: 0.0168, acc: 99.70 %

Epoch    25: reducing learning rate of group 0 to 1.5259e-08.
[Epoch 26/30] loss: 0.0980, acc: 96.48 %
	(val) loss: 0.0217, acc: 99.70 %

[Epoch 27/30] loss: 0.0969, acc: 96.61 %
	(val) loss: 0.0187, acc: 99.70 %

[Epoch 28/30] loss: 0.1010, acc: 96.48 %
	(val) loss: 0.0174, acc: 99.70 %

[Epoch 29/30] loss: 0.1004, acc: 96.54 %
	(val) loss: 0.0194, acc: 99.70 %

[Epoch 30/30] loss: 0.1001, acc: 96.69 %
	(val) loss: 0.0152, acc: 99.80 %

    - found new best validation accuracy

dumping logger to pickle file..
max validation accuracy 99.80 % was obtained after 30 epochs
